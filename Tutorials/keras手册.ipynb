{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "from keras import losses\n",
    "from keras import metrics\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/star/GIT-PROJECTS/MATH',\n",
       " '/opt/anaconda3/envs/kaggle/lib/python37.zip',\n",
       " '/opt/anaconda3/envs/kaggle/lib/python3.7',\n",
       " '/opt/anaconda3/envs/kaggle/lib/python3.7/lib-dynload',\n",
       " '',\n",
       " '/opt/anaconda3/envs/kaggle/lib/python3.7/site-packages',\n",
       " '/opt/anaconda3/envs/kaggle/lib/python3.7/site-packages/IPython/extensions',\n",
       " '/home/star/.ipython']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_functions = [losses.mean_squared_error,\n",
    "                 losses.mean_absolute_error,\n",
    "                 losses.mean_absolute_percentage_error,\n",
    "                 losses.mean_squared_logarithmic_error,\n",
    "                 losses.squared_hinge,\n",
    "                 losses.hinge,\n",
    "                 losses.categorical_crossentropy,\n",
    "                 losses.binary_crossentropy,\n",
    "                 losses.kullback_leibler_divergence,\n",
    "                 losses.poisson,\n",
    "                 losses.cosine_proximity,\n",
    "                 losses.logcosh,\n",
    "                 losses.categorical_hinge]\n",
    "all_classes = [\n",
    "    losses.Hinge,\n",
    "    losses.SquaredHinge,\n",
    "    losses.CategoricalHinge,\n",
    "    losses.Poisson,\n",
    "    losses.LogCosh,\n",
    "    losses.KLDivergence,\n",
    "    losses.Huber,\n",
    "    # losses.SparseCategoricalCrossentropy,\n",
    "    losses.BinaryCrossentropy,\n",
    "    losses.MeanSquaredLogarithmicError,\n",
    "    losses.MeanAbsolutePercentageError,\n",
    "    losses.MeanAbsoluteError,\n",
    "    losses.MeanSquaredError,\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#均方误差(MSE)是最常用的回归损失函数，计算方法是求预测值与真实值之间距离的平方和。\n",
    "#MAE是目标值和预测值之差的绝对值之和。其只衡量了预测值误差的平均模长  \n",
    "$$SSE(y_i,\\hat{y_i}) = \\sum_{i=1}^n(y_i - \\hat{y_i})^2 $$\n",
    "\n",
    "$$MSE(y_i,\\hat{y_i}) = \\frac{\\sum_{i=1}^n(y_i - \\hat{y_i})^2}{n}$$\n",
    "\n",
    "$$MAE(y_i,\\hat{y_i}) = \\sum_{i=1}^n|y_i - \\hat{y_i}|$$\n",
    "\n",
    "$$MSLE(y_i,\\hat{y_i}) = \\frac{\\sum_{i=1}^n(log(y_i+1) - log(\\hat{y_i}+1))^2}{n}$$\n",
    "\n",
    "$$Squared-Hinge(y_i,\\hat{y_i}) = \\frac{\\sum_{i=1}^nmax(1-y_i*\\hat{y_i},0)^2}{n}$$\n",
    "\n",
    "$$hinge(y_i,\\hat{y_i}) = \\frac{\\sum_{i=1}^nmax(1-y_i*\\hat{y_i},0)}{n}$$\n",
    "\n",
    "#Hinge:取1减去预测值与实际值乘积的结果与0比相对大的值的的累加均值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #自定义成本函数类  \n",
    " __call__ 方法表示该类实例化的对象是可调用对象（callable），我们平时自定义的函数、内置函数和类都属于可调用对象。  \n",
    " 但凡是可以把一对括号()应用到某个对象身上都可称之为可调用对象  \n",
    " 判断对象是否为可调用对象可以用函数 callable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MSE_MAE_Loss(object):\n",
    "    def __init__(self,mse_fraction):\n",
    "        self.mse_fraction = mse_fraction\n",
    "        \n",
    "    def __call__(self, y_true, y_pred, sample_weight=None):\n",
    "        return (self.mse_fraction * losses.mse(y_true, y_pred) +\n",
    "            (1 - self.mse_fraction) * losses.mae(y_true, y_pred))\n",
    "    \n",
    "    def get_config(self):\n",
    "        return {'mse_fraction': self.mse_fraction}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = MSE_MAE_Loss(0.6)\n",
    "y_true = np.array([1,2,6])\n",
    "y_true\n",
    "y_pred = np.array([2,3,8])\n",
    "result = loss(y_true, y_pred)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.generic_utils import custom_object_scope\n",
    "with custom_object_scope({'MSE_MAE_loss': MSE_MAE_Loss}):\n",
    "    serialized = losses.serialize(loss)\n",
    "serialized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#测试成本函数\n",
    "mse = keras.losses.mse\n",
    "loss = mse([0., 0., 1., 1.], [1., 1., 1., 0.])\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(loss))\n",
    "    \n",
    "mse_cls = keras.losses.MeanSquaredError() #此处括号不能省略\n",
    "loss_1 = mse_cls([0., 0., 1., 1.], [1., 1., 1., 0.])\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(loss_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#实现msle,np.clip是截取最小值和最大值，最小值是sys.float_info.epsilon，不限制最大值\n",
    "import sys\n",
    "y_true = np.array([1,2,6])\n",
    "y_pred = np.array([2,3,8])\n",
    "np.clip(y_pred,sys.float_info.epsilon,None)\n",
    "first_log = np.log(np.clip(y_pred,sys.float_info.epsilon,None)+1.)\n",
    "second_log = np.log(np.clip(y_true,sys.float_info.epsilon,None)+1.)\n",
    "result = np.mean(np.square(first_log-second_log),axis=-1)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.float_info.epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 取1减去预测值与实际值的乘积的结果与0比相对大的值的累加均值\n",
    "(max(1-y_true*y_pred,0)).mean(axis=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_obj = metrics.MeanSquaredError(name='my_mse',dtype='int32')\n",
    "mse_obj2 = metrics.MeanSquaredError.from_config(mse_obj.get_config())\n",
    "print(mse_obj2.name)\n",
    "print(mse_obj2.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "y_true = ((0, 1, 0, 1, 0), (0, 0, 1, 1, 1),\n",
    "              (1, 1, 1, 1, 0), (0, 0, 0, 0, 1))\n",
    "y_pred = ((0, 0, 1, 1, 0), (1, 1, 1, 1, 1),\n",
    "          (0, 1, 0, 1, 0), (1, 1, 1, 1, 1))\n",
    "'''\n",
    "from tensorflow.python.framework import ops\n",
    "ops.reset_default_graph()\n",
    "y_true = tf.constant([[0, 1, 0, 1, 0], [0, 0, 1, 1, 1],\n",
    "           [1, 1, 1, 1, 0], [0, 0, 0, 0, 1]])\n",
    "\n",
    "y_pred = tf.constant([[0, 0, 1, 1, 0], [1, 1, 1, 1, 1],\n",
    "           [0, 1, 0, 1, 0], [1, 1, 1, 1, 1]])\n",
    "y_true\n",
    "y_pred\n",
    "sample_weight = tf.constant([1., 1.5, 2., 2.5])\n",
    "\n",
    "mse_obj = metrics.MeanSquaredError(dtype='int32')\n",
    "result = mse_obj(y_true,y_pred,sample_weight=sample_weight)\n",
    "print(result)\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer() \n",
    "    sess.run(init)\n",
    "    sess.run(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "print constant\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([ 4.        ,  3.8367348 ,  3.6734693 ,  3.510204  ,  3.3469388 ,\n",
       "        3.1836734 ,  3.0204082 ,  2.857143  ,  2.6938777 ,  2.5306122 ,\n",
       "        2.367347  ,  2.2040815 ,  2.0408163 ,  1.8775511 ,  1.7142859 ,\n",
       "        1.5510204 ,  1.3877552 ,  1.2244899 ,  1.0612245 ,  0.89795923,\n",
       "        0.734694  ,  0.57142854,  0.4081633 ,  0.24489808,  0.08163261,\n",
       "       -0.08163261, -0.24489784, -0.40816307, -0.5714283 , -0.734694  ,\n",
       "       -0.89795923, -1.0612245 , -1.2244897 , -1.3877549 , -1.5510201 ,\n",
       "       -1.7142854 , -1.8775511 , -2.0408163 , -2.2040815 , -2.3673468 ,\n",
       "       -2.530612  , -2.6938772 , -2.857143  , -3.0204082 , -3.1836734 ,\n",
       "       -3.3469386 , -3.5102038 , -3.673469  , -3.8367348 , -4.        ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hinge result\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f5155dc2c18>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_vals = tf.linspace(-3., 5., 50)\n",
    "target = tf.constant(1.)\n",
    "targets = tf.fill([50,], 1.)\n",
    "\n",
    "hinge_y_vals = tf.maximum(0., 1. - tf.multiply(targets, x_vals))\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    x_array = sess.run(x_vals)\n",
    "    print(\"print constant\")\n",
    "    sess.run(targets)\n",
    "    sess.run(1. - tf.multiply(targets, x_vals))\n",
    "    print(\"hinge result\")\n",
    "    hinge_y_out = sess.run(hinge_y_vals)\n",
    "    \n",
    "plt.plot(x_array, hinge_y_out, 'b-', label='Hinge Loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 精确率的计算公式\n",
    "$$ Precision = \\frac{truePositive}{truePositive + falsePositive} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array([[1,1,1,0],\n",
    "                   [1,1,1,0],\n",
    "                   [1,1,1,0],\n",
    "                   [1,1,1,0]], dtype=np.uint8)\n",
    "\n",
    "predictions = np.array([[1,0,0,0],\n",
    "                        [1,1,0,0],\n",
    "                        [1,1,1,0],\n",
    "                        [0,1,1,1]], dtype=np.uint8)\n",
    "\n",
    "n_batches = len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "8\n",
      "Precision :0.8889\n"
     ]
    }
   ],
   "source": [
    "#计算精确率\n",
    "#TP+FP=9,TP=8,FP=1\n",
    "pred_p = (predictions > 0).sum()\n",
    "print(pred_p)\n",
    "true_p = (labels*predictions > 0).sum()\n",
    "print(true_p)\n",
    "precision = true_p / pred_p\n",
    "print(\"Precision :%1.4f\" %(precision))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于海量数据集，它不能一次扩展到大到无法装入内存的大型数据集。\n",
    "为了使其具有可伸缩性，我们希望使评估度量能够使用每一批新的预测和标签以增量方式更新自身。\n",
    "为此，我们需要跟踪两个值。\n",
    "* 正确预测的正样本数量\n",
    "* 预测样本中所有正样本的数量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_TRUE_P = 0\n",
    "N_PRED_P = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_TRUE_P = 0\n",
    "N_PRED_P = 0\n",
    "\n",
    "def reset_running_variables():\n",
    "    \"\"\" Resets the previous values of running variables to zero \"\"\"\n",
    "    global N_TRUE_P, N_PRED_P\n",
    "    N_TRUE_P = 0\n",
    "    c = 0\n",
    "    print(f\"N_TRUE_P:{N_TRUE_P},N_PRED_P:{N_PRED_P}\")\n",
    "\n",
    "def update_running_variables(labs, preds):\n",
    "    global N_TRUE_P, N_PRED_P\n",
    "    N_TRUE_P += ((labs * preds) > 0).sum()\n",
    "    N_PRED_P += (preds > 0).sum()\n",
    "    print(f\"N_TRUE_P:{N_TRUE_P},N_PRED_P:{N_PRED_P}\")\n",
    "\n",
    "def calculate_precision():\n",
    "    global N_TRUE_P, N_PRED_P\n",
    "    return float (N_TRUE_P) / N_PRED_P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N_TRUE_P:0,N_PRED_P:0\n",
      "----------\n",
      "labels:[1 1 1 0],prdes:[1 0 0 0]\n",
      "N_TRUE_P:1,N_PRED_P:1\n",
      "labels:[1 1 1 0],prdes:[1 1 0 0]\n",
      "N_TRUE_P:3,N_PRED_P:3\n",
      "labels:[1 1 1 0],prdes:[1 1 1 0]\n",
      "N_TRUE_P:6,N_PRED_P:6\n",
      "labels:[1 1 1 0],prdes:[0 1 1 1]\n",
      "N_TRUE_P:8,N_PRED_P:9\n",
      "[NP] SCORE: 0.8889\n"
     ]
    }
   ],
   "source": [
    "# 整体精确率\n",
    "reset_running_variables()\n",
    "\n",
    "\n",
    "print(\"----------\")\n",
    "for i in range(n_batches):\n",
    "    print(f\"labels:{labels[i]},prdes:{predictions[i]}\")\n",
    "    update_running_variables(labs=labels[i], preds=predictions[i])\n",
    "\n",
    "precision = calculate_precision()\n",
    "print(\"[NP] SCORE: %1.4f\" %precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N_TRUE_P:0,N_PRED_P:0\n",
      "N_TRUE_P:1,N_PRED_P:1\n",
      "- [NP] batch 0 score: 1.0000\n",
      "N_TRUE_P:0,N_PRED_P:1\n",
      "N_TRUE_P:2,N_PRED_P:3\n",
      "- [NP] batch 1 score: 0.6667\n",
      "N_TRUE_P:0,N_PRED_P:3\n",
      "N_TRUE_P:3,N_PRED_P:6\n",
      "- [NP] batch 2 score: 0.5000\n",
      "N_TRUE_P:0,N_PRED_P:6\n",
      "N_TRUE_P:2,N_PRED_P:9\n",
      "- [NP] batch 3 score: 0.2222\n"
     ]
    }
   ],
   "source": [
    "# 计算批准确率\n",
    "for i in range(n_batches):\n",
    "    reset_running_variables()\n",
    "    update_running_variables(labs=labels[i], preds=predictions[i])\n",
    "    prec = calculate_precision()\n",
    "    print(\"- [NP] batch %d score: %1.4f\" %(i, prec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.8888889"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TF] SCORE: 0.8889\n"
     ]
    }
   ],
   "source": [
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    tf_label = tf.placeholder(dtype=tf.int32, shape=[None])\n",
    "    tf_prediction = tf.placeholder(dtype=tf.int32, shape=[None])\n",
    "\n",
    "    tf_metrics, tf_metric_update = tf.metrics.precision(tf_label,tf_prediction, name=\"my_metric\")\n",
    "    #LOCAL_VARIABLES每台计算机的局部变量对象的子集\n",
    "    running_vars = tf.get_collection(tf.GraphKeys.LOCAL_VARIABLES, scope=\"my_metric\")\n",
    "    \n",
    "    running_vars_initializer = tf.variables_initializer(var_list=running_vars)\n",
    "    \n",
    "with tf.Session(graph=graph) as session:\n",
    "    #最常见的初始化模式是使用便利功能global_variables_initializer（）向图形添加操作来初始化所有变量。然后在启动图后运行该操作。\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    \n",
    "    #初始化/重置正在运行的变量\n",
    "    session.run(running_vars_initializer)\n",
    "    \n",
    "    \n",
    "    for i in range(n_batches):\n",
    "        # Update the running variables on new batch of samples\n",
    "        feed_dict={tf_label: labels[i], tf_prediction: predictions[i]}\n",
    "        session.run(tf_metric_update, feed_dict=feed_dict)\n",
    "\n",
    "    # Calculate the score\n",
    "    score = session.run(tf_metrics)\n",
    "    print(\"[TF] SCORE: %1.4f\" %score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATCH [TF] SCORE: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATCH [TF] SCORE: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATCH [TF] SCORE: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6666667"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATCH [TF] SCORE: 0.6667\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=graph) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for i in range(n_batches):\n",
    "        sess.run(running_vars_initializer)\n",
    "        \n",
    "        feed_dict = {tf_label: labels[i], tf_prediction: predictions[i]}\n",
    "        sess.run(tf_metric_update, feed_dict = feed_dict)\n",
    "        \n",
    "        score = sess.run(tf_metrics)\n",
    "        print(\"BATCH [TF] SCORE: %1.4f\" %score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在tf.metrics.precision_at_k这个函数中，对于predictions会根据输入的k值进行top_k操作。 对应上面的代码中，当k=10，即对rec = tf.constant([[7, 5, 10, 6, 3, 1, 8, 12, 31, 88]], tf.int64) 所有的样本进行排序，进而在函数中实际运用的是rec中样本数值从大到小排列的索引值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PRECSION_1]:  nan\n",
      "[UPDATE_OP_1]: 0.2\n",
      "[STREAM_VARS_1]: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 8.0]\n",
      "[PRECISION_2]: 0.2\n",
      "[UPDATE_OP_2]: 0.15\n",
      "[STREAM_VARS_2]: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 17.0]\n",
      "[PRECISION_3]: 0.15\n",
      "[UPDATE_OP_3]: 0.16666666666666666\n",
      "[STREAM_VARS_3]: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 25.0]\n",
      "[PRECISION_4]: 0.16666666666666666\n",
      "[UPDATE_OP_4]: 0.2\n",
      "[STREAM_VARS_5]: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 32.0]\n"
     ]
    }
   ],
   "source": [
    "rel = tf.placeholder(tf.int64, [1,3])\n",
    "rec = tf.constant([[7, 5, 10, 6, 3, 1, 8, 12, 31, 88]], tf.int64) \n",
    "#k表明需要对多少个预测样本进行排序\n",
    "precision, update_op = tf.metrics.precision_at_k(rel, rec, 10)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    \n",
    "    stream_vars = [i for i in tf.local_variables()]\n",
    "\n",
    "    #tf.metrics.precision维护两个变量true_positives和false_positives,每个值初始值为zero.所有该步输出为'nan'\n",
    "    print(\"[PRECSION_1]: \",sess.run(precision, {rel:[[1,5,10]]}))\n",
    "    \n",
    "    print(\"[UPDATE_OP_1]:\",sess.run(update_op, {rel:[[1,5,10]]}))\n",
    "    \n",
    "    # Get true positive rate and false positive rate\n",
    "    print(\"[STREAM_VARS_1]:\",sess.run(stream_vars))\n",
    "    \n",
    "    print(\"[PRECISION_2]:\",sess.run(precision,{rel:[[1,10,15]]})) \n",
    "    \n",
    "    print(\"[UPDATE_OP_2]:\",sess.run(update_op,{rel:[[1,10,15]]}))\n",
    "    print(\"[STREAM_VARS_2]:\",sess.run(stream_vars))\n",
    "    \n",
    "    print(\"[PRECISION_3]:\",sess.run(precision,{rel:[[1,3,10]]}))    \n",
    "    print(\"[UPDATE_OP_3]:\",sess.run(update_op,{rel:[[1,3,10]]}))\n",
    "    print(\"[STREAM_VARS_3]:\",sess.run(stream_vars))\n",
    "    \n",
    "    print(\"[PRECISION_4]:\",sess.run(precision,{rel:[[1,3,5]]}))    \n",
    "    print(\"[UPDATE_OP_4]:\",sess.run(update_op,{rel:[[1,3,5]]}))\n",
    "    print(\"[STREAM_VARS_4]:\",sess.run(stream_vars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF_MAP 0.4333333333333333\n",
      "STREAM_VARS [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 2.1666666666666665]\n",
      "TMP_RANK TopKV2(values=array([[0.6 , 0.2 , 0.1 ],\n",
      "       [0.8 , 0.1 , 0.05],\n",
      "       [0.4 , 0.3 , 0.2 ],\n",
      "       [0.6 , 0.25, 0.1 ],\n",
      "       [0.6 , 0.2 , 0.1 ]], dtype=float32), indices=array([[2, 1, 0],\n",
      "       [0, 2, 1],\n",
      "       [1, 0, 3],\n",
      "       [0, 1, 2],\n",
      "       [2, 1, 0]], dtype=int32))\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "y_true = np.array([[2], [1], [0], [3], [0]]).astype(np.int64)\n",
    "y_true = tf.identity(y_true)\n",
    "\n",
    "y_pred = np.array([[0.1, 0.2, 0.6, 0.1],\n",
    "                   [0.8, 0.05, 0.1, 0.05],\n",
    "                   [0.3, 0.4, 0.1, 0.2],\n",
    "                   [0.6, 0.25, 0.1, 0.05],\n",
    "                   [0.1, 0.2, 0.6, 0.1]\n",
    "                   ]).astype(np.float32)\n",
    "y_pred = tf.identity(y_pred)\n",
    "\n",
    "_, m_ap = tf.metrics.average_precision_at_k(y_true, y_pred, 3)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "\n",
    "    stream_vars = [i for i in tf.local_variables()]\n",
    "    #sess.run(stream_vars)\n",
    "\n",
    "    tf_map = sess.run(m_ap)\n",
    "    print(\"TF_MAP\",tf_map)\n",
    "    \n",
    "    print(\"STREAM_VARS\",(sess.run(stream_vars)))\n",
    "    \n",
    "    tmp_rank = tf.nn.top_k(y_pred,3)\n",
    "    print(\"TMP_RANK\",sess.run(tmp_rank))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 分类Loss\n",
    "logits=$[2,7,5]$\n",
    "softmax将logits转换成概率,就是按照公式:$\\frac{e^x}{\\sum{e^x}}$\n",
    "$$softmax(logits)=[\\frac{e^2}{e^2+e^7+e^5},\\frac{e^5}{e^2+e^7+e^5},\\frac{e^7}{e^2+e^7+e^5}]$$\n",
    "计算结果为：$[0.00589975 0.8756006 0.11849965]$\n",
    "\n",
    "交叉熵公式：$-\\sum_{i=1}^n{y_i}*log(\\hat{y_i})$\n",
    "计算结果是：−0×log(0.00589975)−1×log(0.8756006)−0×log(0.11849965)=0.6355716"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-219e941e7a79>:10: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "[0.00589975 0.8756006  0.11849965]\n",
      "[-5.1328454  -0.13284525 -2.1328452 ]\n",
      "0.13284527\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "#交叉熵\n",
    "logits = tf.constant([2,7,5],dtype=tf.float32)\n",
    "labels = [0,1,0]\n",
    "#对logits使用softmax,[0.00589975 0.8756006  0.11849965]\n",
    "res1 = tf.nn.softmax(logits) \n",
    "# 交叉熵损失中的各个对数部分,[-5.1328454  -0.13284525 -2.1328452 ]\n",
    "res2 = tf.log(res1) \n",
    "# 交叉熵损失,0.13284527\n",
    "res3 = tf.nn.softmax_cross_entropy_with_logits(logits=logits,labels=labels)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "\tres1,res2,res3 = sess.run([res1,res2,res3])\n",
    "\tprint(res1)\n",
    "\tprint(res2)\n",
    "\tprint(res3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一般训练时batch size不会为设为1, \n",
    "要使用tf.reduce_mean()来对tf.softmax_cross_entropy_with_logits()的结果取平均,得到关于样本的平均交叉熵损失。  \n",
    "$$logits=[[2,7,5],[6,3,4]] , labels=[[0,1,0],[1,0,0]]$$\n",
    "使用tf.softmax_cross_entropy_with_logits(),  \n",
    "计算后得到$[2,7,5],[6,3,4]$这两个样本的交叉熵损失,  \n",
    "再使用tf.reduce_mean()取平均\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.00589975, 0.8756006 , 0.11849965],\n",
       "        [0.8437947 , 0.04201007, 0.11419519]], dtype=float32),\n",
       " array([[-5.1328454 , -0.13284525, -2.1328452 ],\n",
       "        [-0.16984606, -3.169846  , -2.169846  ]], dtype=float32),\n",
       " array([0.13284527, 0.16984604], dtype=float32),\n",
       " 0.15134566]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = tf.constant([[2,7,5],[6,3,4]],dtype=tf.float32)\n",
    "labels = [[0,1,0],[1,0,0]]\n",
    "\n",
    "res1 = tf.nn.softmax(y_pred)\n",
    "res2 = tf.log(res1)\n",
    "res3 = tf.nn.softmax_cross_entropy_with_logits(logits=y_pred,labels=labels)\n",
    "res4 = tf.reduce_mean(res3)\n",
    "with tf.Session() as sess:\n",
    "    sess.run([res1,res2,res3,res4])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Kaggle",
   "language": "python",
   "name": "kaggle"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
